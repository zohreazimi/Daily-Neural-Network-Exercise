{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc55563c-87f6-4ce9-a62b-0357cb9ddbd8",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "برای استفاده از خودِ <b>PyTorch</b>، یعنی همه‌ی امکانات اصلی مثل ساخت <b>Tensor</b>‌ها و اجرای عملیات روی <b>GPU/CPU</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a33260-4109-4f1f-8eec-e3fe7edd2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fc3dc-2be3-42e7-a4cf-2cd4727c267c",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط برای وارد کردن <b>torch.nn</b> است؛ \n",
    "کتابخانه‌ای که اجازه می‌دهد لایه‌های شبکه عصبی مانند <b>Conv2d</b> و <b>Pooling</b> را بسازیم.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e0631c-39c6-4b64-a7c2-3766fa7d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72a654-5fc3-481b-8957-1d89ccc2d047",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط برای وارد کردن <b>torch.nn.functional</b> است؛\n",
    "که توابع آماده مانند <b>ReLU</b>، <b>softmax</b> و سایر عملیات ریاضی روی لایه‌ها را فراهم می‌کند.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0920a1-4168-4392-8061-bf03a7736a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79de6b3-ba39-4166-b288-e696eeacac70",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط برای وارد کردن <b>torch.optim</b> است؛\n",
    "که به ما اجازه می‌دهد بهینه‌سازهایی مانند <b>SGD</b> و <b>Adam</b> را برای بروزرسانی وزن‌ها استفاده کنیم.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10901030-e739-44c4-8a11-19cbd6e1ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb1f15-9901-45c5-88b4-e1ff8eecfe4b",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط برای وارد کردن <b>torchvision</b> است؛\n",
    "کتابخانه‌ای که دیتاست‌ها و ترنسفورم‌های آماده تصاویر مانند <b>MNIST</b> و <b>CIFAR</b> را فراهم می‌کند.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be33281-7403-4fa1-9e0b-cf6646bc0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c142861-063b-422d-9727-f4963ea3b8fe",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط برای وارد کردن <b>torchvision.transforms</b> است؛\n",
    "که امکان انجام تبدیل‌ها و پیش‌پردازش تصاویر مانند <b>Resize</b>، <b>Normalize</b> و تبدیل به <b>Tensor</b> را فراهم می‌کند.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0555e366-3c14-4337-a434-a7f3cd58cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dacda4-e6d4-4cb7-b71e-bb0902e771be",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط برای تعریف یک کلاس <b>CNN</b> ساده است.\n",
    "سازنده <b>__init__</b> آماده می‌شود تا بتوانیم لایه‌ها را در آن اضافه کنیم.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29262f-2c23-4aeb-b61d-ba7555f09cb7",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "استفاده از <b>super()</b> در اینجا برای فراخوانی سازنده کلاس پایه <b>nn.Module</b> است.\n",
    "این کار لازم است تا <b>CNN</b> ما بتواند تمام امکانات داخلی <b>nn.Module</b> مانند مدیریت پارامترها و ثبت لایه‌ها را داشته باشد.\n",
    "بدون <b>super()</b> ممکن است شبکه بدرستی عمل نکند یا خطا بدهد.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0f1f6e-4798-4984-bba7-4bac83ee5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module): #1\n",
    "    def __init__(self): #1\n",
    "        super(SimpleCNN, self).__init__() #1\n",
    "        # Conv layer\n",
    "        self.conv1 = nn.Conv2d( #2\n",
    "            in_channels=1,  #2\n",
    "            out_channels=16, #2\n",
    "            kernel_size=3, #2\n",
    "            stride=1, #2\n",
    "            padding=1 #2\n",
    "        ) #2\n",
    "        self.relu = nn.ReLU() #3\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #5\n",
    "        self.conv2 = nn.Conv2d( #7\n",
    "            in_channels=16,  #7\n",
    "            out_channels=32,  #7\n",
    "            kernel_size=3,  #7\n",
    "            stride=1,  #7\n",
    "            padding=1 #7\n",
    "        ) #7\n",
    "        self.relu = nn.ReLU() #7\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) #9\n",
    "        # Dense layer\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128) #11\n",
    "        self.relu_fc1 = nn.ReLU() #12\n",
    "        self.fc2 = nn.Linear(128, 10) #13\n",
    "\n",
    "\n",
    "    def forward(self, x): #4\n",
    "        x = self.conv1(x) #4\n",
    "        x = self.relu(x) #4\n",
    "        x = self.pool(x) #6\n",
    "        x = self.conv2(x) #8\n",
    "        x = self.relu(x) #8\n",
    "        x = self.pool2(x) #10\n",
    "        x = torch.flatten(x, 1) #11\n",
    "        x = self.fc1(x) #11\n",
    "        x = self.relu_fc1(x) #11\n",
    "        x = self.fc2(x) #14\n",
    "        return x #4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76765d38-2fcc-46d7-b2af-f351ba0a1299",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.conv1 = nn.Conv2d(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76a1a6-c550-4a61-b856-445bded18541",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک لایه <b>Conv2d</b> اول در <b>CNN</b> ایجاد می‌کند.\n",
    "- <b>in_channels=1</b> : تعداد کانال‌های ورودی (مثلاً تصاویر سیاه‌وسفید)  \n",
    "- <b>out_channels=16</b> : تعداد فیلترهای خروجی  \n",
    "- <b>kernel_size=3</b> : اندازه کرنل 3×3  \n",
    "- <b>stride=1</b> : گام حرکت کرنل  \n",
    "- <b>padding=1</b> : اضافه کردن لبه‌ها برای حفظ ابعاد\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f0245-ab63-43b7-87a5-354d0c3f8131",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "تعداد <b>out_channels=16</b> در لایه اول <b>Conv2d</b> یک انتخاب متداول و منطقی است.  \n",
    "- هر فیلتر (کانال خروجی) یک ویژگی خاص تصویر را استخراج می‌کند، پس با 16 فیلتر، شبکه می‌تواند 16 ویژگی مختلف را یاد بگیرد.  \n",
    "- اگر تعداد فیلترها کمتر باشد (مثلاً 4 یا 8)، ممکن است شبکه نتواند جزئیات تصویر را به خوبی تشخیص دهد.  \n",
    "- اگر تعداد فیلترها خیلی زیاد باشد (مثلاً 64 یا 128)، حجم محاسبات و مصرف حافظه افزایش می‌یابد و برای لایه‌های ابتدایی معمولاً لازم نیست اینقدر فیلتر داشته باشیم.  \n",
    "بنابراین 16 یک تعادل مناسب بین <b>قدرت استخراج ویژگی</b> و <b>کارایی محاسباتی</b> ایجاد می‌کند و انتخاب رایجی برای لایه اول CNN است.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcda9c-1689-4dd8-b146-1cac22f36047",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "اندازه <b>kernel_size=3</b> یعنی فیلتر 3×3 روی تصویر اعمال می‌شود.  \n",
    "- فیلتر 3×3 یک انتخاب متداول در CNNهاست زیرا به اندازه کافی کوچک است تا جزئیات محلی تصویر را بگیرد،  \n",
    "و همزمان محاسبات زیادی نیاز ندارد.  \n",
    "- اندازه بزرگتر (مثلاً 5×5 یا 7×7) ویژگی‌های وسیع‌تر را می‌گیرد ولی محاسبات سنگین‌تر می‌شود و ممکن است جزئیات ریز را از دست بدهد.  \n",
    "- بنابراین <b>3×3</b> تعادل خوبی بین دقت و کارایی محاسباتی ایجاد می‌کند و در اکثر شبکه‌ها استفاده می‌شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23576640-ba4c-4cad-80b8-0e42c6f798c4",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "پارامتر <b>stride=1</b> مشخص می‌کند فیلتر <b>Conv2d</b> در هر حرکت فقط یک پیکسل به جلو برود.  \n",
    "- با <b>stride=1</b> تصویر خروجی تقریباً همان ابعاد ورودی را حفظ می‌کند (به شرط اینکه padding مناسب باشد).  \n",
    "- اگر stride بزرگتر باشد (مثلاً 2 یا 3)، اندازه خروجی کاهش می‌یابد و اطلاعات محلی جزئی از بین می‌رود.  \n",
    "- بنابراین <b>stride=1</b> انتخاب رایج در لایه‌های ابتدایی CNN است تا جزئیات تصویر حفظ شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3566d7-06e5-4644-bd03-e7a4a1b62ba6",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "پارامتر <b>padding=1</b> مشخص می‌کند که اطراف تصویر <b>یک لایه صفر</b> اضافه شود.  \n",
    "- این کار باعث می‌شود بعد از اعمال <b>Conv2d</b>، ابعاد تصویر تقریباً همانند ورودی باقی بماند.  \n",
    "- بدون padding، اندازه تصویر خروجی کوچک‌تر می‌شود و لبه‌های تصویر کمتر در فرآیند یادگیری در نظر گرفته می‌شوند.  \n",
    "- بنابراین <b>padding=1</b> تعادل خوبی بین حفظ ابعاد و استخراج ویژگی‌ها ایجاد می‌کند و در لایه‌های ابتدایی CNN معمولاً استفاده می‌شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8861a4cb-f066-442b-ba09-191656529971",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61374e0-e2e9-4cb4-a7c7-9a0a2e24bb73",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک <b>تابع فعال‌سازی ReLU</b> برای <b>CNN</b> ایجاد می‌کند.\n",
    "ReLU به شبکه اجازه می‌دهد تا <b>غیرخطی بودن</b> داشته باشد و یادگیری ویژگی‌ها بهتر انجام شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0bf89-5495-4e4c-95c0-b01ae7b4c923",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "همیشه بعد از هر لایه <b>Conv2d</b> لازم نیست تابع فعال‌سازی گذاشته شود،  \n",
    "اما معمولاً در اکثر شبکه‌های CNN بعد از لایه پیچشی یک تابع فعال‌سازی مانند <b>ReLU</b> قرار می‌دهند.  \n",
    "- هدف این است که شبکه <b>غیرخطی</b> شود و بتواند ویژگی‌های پیچیده‌تر تصویر را یاد بگیرد.  \n",
    "- در برخی لایه‌ها یا معماری‌ها ممکن است فعال‌سازی بعدی اعمال نشود، مثلاً در لایه خروجی برای برخی وظایف خاص.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52296425-d579-45c0-88bd-a285afd335f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.pool = nn.MaxPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd23313-972f-45d8-8bb1-5e4c94884f91",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک لایه <b>MaxPool2d</b> در <b>CNN</b> ایجاد می‌کند.  \n",
    "- <b>kernel_size=2</b> : اندازه پنجره 2×2 برای pooling  \n",
    "- <b>stride=2</b> : حرکت پنجره ۲ پیکسل به جلو  \n",
    "- وظیفه <b>Pooling</b> کاهش ابعاد و تمرکز روی ویژگی‌های مهم است.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ca495-838e-4925-a4e4-fdc0245f9389",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## def forward(self, x): ... return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6e391-fde0-4481-965a-a93d09b63cf7",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "متد <b>forward</b> مسیر عبور داده‌ها در <b>CNN</b> را مشخص می‌کند.  \n",
    "- <b>x = self.conv1(x)</b> : داده ورودی از لایه پیچشی اول عبور می‌کند.  \n",
    "- <b>x = self.relu(x)</b> : تابع فعال‌سازی ReLU روی خروجی اعمال می‌شود.  \n",
    "- <b>return x</b> : خروجی نهایی این مرحله بازگردانده می‌شود.  \n",
    "بدون <b>forward</b>، شبکه نمی‌تواند پیش‌بینی کند یا آموزش ببیند.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3041a9d-3760-479b-bb20-59c4a9b90d47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## def forward(self, x): x = self.pool(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32371f-0453-4802-82a9-65b993ec3fea",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط در <b>forward</b> قرار دارد و لایه <b>MaxPool2d</b> را اعمال می‌کند.  \n",
    "- کاهش ابعاد خروجی و تمرکز روی ویژگی‌های مهم  \n",
    "- کمک به کاهش محاسبات و جلوگیری از Overfitting\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4f94b-3a6b-4187-a3f7-11fde39382da",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "<b>Overfitting</b> زمانی رخ می‌دهد که شبکه <b>خیلی خوب روی داده‌های آموزش</b> یاد می‌گیرد ولی توانایی تعمیم به داده‌های جدید را ندارد.  \n",
    "- به عبارتی، مدل جزئیات نویز و ویژگی‌های خاص آموزش را یاد می‌گیرد و عملکردش روی داده‌های تست ضعیف می‌شود.  \n",
    "- روش‌هایی مانند <b>MaxPooling</b>، <b>Dropout</b> و <b>Regularization</b> به کاهش Overfitting کمک می‌کنند.\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a956ec2-6a34-4ca9-a4e7-eba6602ca4a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "154ee430-57f2-4b12-af3e-fdf3d6b7aafb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  self.conv2 = nn.Conv2d(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6216c41-3888-4081-8118-e1584af9e0fd",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "اضافه کردن لایه <b>Conv2d دوم</b> در <b>CNN</b> به این دلیل است که:  \n",
    "- لایه اول ویژگی‌های ساده تصویر مانند لبه‌ها و گوشه‌ها را یاد می‌گیرد.  \n",
    "- لایه دوم می‌تواند ویژگی‌های پیچیده‌تر و ترکیبی را استخراج کند، مانند بافت‌ها و شکل‌های پیچیده.  \n",
    "\n",
    "همچنین توجه داشته باش که بعد از تعریف <b>Conv2</b> در <b>__init__</b>،  \n",
    "در <b>forward</b> هم باید این لایه استفاده شود تا خروجی آن محاسبه و به مراحل بعدی شبکه ارسال شود:  \n",
    "<code>\n",
    "x = self.conv2(x)  \n",
    "x = self.relu(x)\n",
    "</code>\n",
    "بدون استفاده در <b>forward</b>، لایه تعریف شده عملاً روی داده‌ها اعمال نمی‌شود.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21beda-5ff7-48fa-871e-9ff7dc802dd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a31113-8e2c-474c-bfcc-c7997e007a57",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک <b>دومین لایه MaxPool2d</b> در <b>CNN</b> ایجاد می‌کند.  \n",
    "- <b>kernel_size=2</b> و <b>stride=2</b> : همانند Pooling اول برای کاهش ابعاد خروجی و تمرکز روی ویژگی‌های مهم.  \n",
    "- اضافه کردن Pooling دوم کمک می‌کند تا ابعاد تصویر کاهش یافته و شبکه برای مراحل Fully Connected آماده شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2da82e-620d-4785-9819-87f0f9dafe84",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "دومین لایه <b>MaxPooling</b> به آماده شدن خروجی برای مرحله <b>Fully Connected</b> کمک می‌کند:<br>\n",
    "<span><b>1. کاهش ابعاد تصویر:</b> بعد از دو لایه Pooling، ارتفاع و عرض Feature Mapها کاهش یافته و تعداد نورون‌ها برای لایه Fully Connected کمتر و قابل مدیریت می‌شود.</span><br>\n",
    "<span><b>2. تمرکز روی ویژگی‌های مهم:</b> MaxPooling ویژگی‌های برجسته را نگه می‌دارد و نویز و جزئیات کم‌اهمیت حذف می‌شوند، تا لایه Dense روی مهم‌ترین ویژگی‌ها تصمیم بگیرد.</span><br>\n",
    "<span><b>3. آماده‌سازی برای Flatten:</b> خروجی آخرین Pooling به بردار یک‌بعدی تبدیل می‌شود تا به لایه Dense وصل شود. بدون Pooling کافی، Flatten ممکن است بردار خیلی بزرگ تولید کند و محاسبات سنگین شود.</span>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e8b94-aecc-46f8-9679-b137d7a69281",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## x = self.pool2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5dc88-8eaf-43ce-8c28-eadc62f8916b",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط در <b>forward</b> خروجی <b>Conv2 + ReLU</b> را با <b>MaxPooling دوم</b> کاهش ابعاد می‌دهد.  \n",
    "- کاهش ابعاد خروجی برای اتصال به لایه Fully Connected  \n",
    "- تمرکز روی ویژگی‌های برجسته و کاهش نویز  \n",
    "- کمک به کاهش حجم محاسبات و جلوگیری از Overfitting\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631ecfc-32a4-495d-9cb7-b1f404a27c90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.fc1 = nn.Linear(32 * 7 * 7, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e614be-581d-433e-942c-6829a6226b96",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک لایه <b>Fully Connected</b> در <b>CNN</b> ایجاد می‌کند.  \n",
    "- <b>32 * 7 * 7</b> : اندازه ورودی برابر با تعداد عناصر خروجی آخرین Pooling است.  \n",
    "- <b>128</b> : تعداد نورون‌های Dense برای یادگیری ویژگی‌های ترکیبی و پیچیده.  \n",
    "- این لایه به شبکه اجازه می‌دهد تصمیم نهایی یا پیش‌بینی را بر اساس ویژگی‌های استخراج شده بگیرد.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58e15b-cd1a-4787-8f57-3f25bec8b0ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.relu_fc1 = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6a3c2-5989-407c-84c0-6c4153b50cc4",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک تابع فعال‌سازی <b>ReLU</b> بعد از لایه <b>Fully Connected اول</b> اضافه می‌کند.  \n",
    "- اعمال <b>ReLU</b> باعث <b>غیرخطی شدن</b> شبکه می‌شود و توانایی یادگیری ویژگی‌های پیچیده‌تر را افزایش می‌دهد.  \n",
    "- بدون فعال‌سازی، لایه Dense صرفاً ترکیبی خطی از ویژگی‌ها را تولید می‌کند و عمق شبکه بی‌معنی می‌شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d4303-6c8a-4973-843c-21a6a27ecd66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## self.fc2 = nn.Linear(128, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02e9bd-9953-4d10-b973-b200fa0e5603",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط یک لایه <b>Fully Connected خروجی</b> در <b>CNN</b> ایجاد می‌کند.  \n",
    "- <b>128</b> : تعداد نورون‌های ورودی از FC1  \n",
    "- <b>10</b> : تعداد کلاس‌ها برای پیش‌بینی (مثلاً ارقام 0 تا 9 در MNIST)  \n",
    "- این لایه نتیجه نهایی شبکه را برای اعمال <b>Softmax</b> یا تابع Loss مناسب آماده می‌کند.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751f542-af9e-47ff-8c81-354073dc6287",
   "metadata": {},
   "source": [
    "## x = self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff7f3e-1b7a-4360-a1ea-c5413cd5b1ac",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط در <b>forward</b> خروجی <b>Fully Connected آخر</b> را محاسبه می‌کند.  \n",
    "- خروجی برداری با طول ۱۰ (تعداد کلاس‌ها) است.  \n",
    "- این خروجی معمولاً برای محاسبه <b>Loss</b> یا اعمال تابع <b>Softmax</b> استفاده می‌شود تا پیش‌بینی نهایی کلاس‌ها انجام شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6a7d0-dee8-4e1e-a423-e06ab0643e27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## نکته مهم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad4b91-a081-427b-9a6b-d445a6453168",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "مسیر عبور داده در شبکه <b>SimpleCNN</b> به صورت زیر است:<br>\n",
    "<b>Conv1 → ReLU → Pool → Conv2 → ReLU → Pool2 → Flatten → FC1 → ReLU → FC2</b><br><br>\n",
    "شبکه آماده است تا یک تصویر MNIST یا مشابه را دریافت کرده و خروجی <b>۱۰ کلاس</b> تولید کند.<br>\n",
    "در مرحله بعد، می‌توانیم یک نمونه تصویر واقعی را از شبکه عبور داده و خروجی پیش‌بینی آن را مشاهده کنیم.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5116e-a332-4253-adf4-ffd64fb4a5b6",
   "metadata": {},
   "source": [
    "## شبکه کامل شد. بریم برای ایجاد نمونه شبکه و ارسال به حافظه سیستم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69f26aa-4460-43f8-9872-ad200cde774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e741298-95db-4b60-9966-941c4b6c924d",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "این خط شبکه <b>SimpleCNN</b> را روی دستگاه مناسب قرار می‌دهد:  \n",
    "- <b>GPU</b> اگر موجود باشد برای محاسبات سریع  \n",
    "- در غیر اینصورت <b>CPU</b>  \n",
    "- این کار باعث می‌شود عملیات آموزش و تست سریع و بهینه انجام شود.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9242e0cb-2e4f-4026-91ce-18ececf201ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# ← اینجا اضافه کن\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4effbaa-c723-4fec-aedf-83c0c8a036ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# تبدیل تصویر به Tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# بارگذاری دیتاست تست MNIST\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=r\"D:\\GitHubProjects\\Daily-Neural-Network-Exercise\\data\\mnist_standard\",  # پوشه استاندارد MNIST\n",
    "    train=False,        # دیتاست تست\n",
    "    download=True,      # اگر فایل‌ها موجود نبود، دانلود می‌کند\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# ساخت DataLoader\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5d67d-6b04-4545-939a-ecf2ab2f018f",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\" style=\"text-align: right; font-family: Tahoma, sans-serif;\">\n",
    "<strong>توضیح دقیق پارامترها:</strong>\n",
    "<ul>\n",
    "<li><b>root</b> : مسیر پوشه‌ای که فایل‌های استاندارد MNIST در آن هستند. این مسیر باید شامل فایل‌هایی مانند <code>train-images-idx3-ubyte</code> باشد.</li>\n",
    "<li><b>train</b> : <code>True</code> برای دیتاست آموزش، <code>False</code> برای دیتاست تست.</li>\n",
    "<li><b>download</b> : <code>True</code> باعث دانلود خودکار MNIST در صورت عدم وجود فایل‌ها می‌شود، <code>False</code> فایل‌ها را استفاده می‌کند.</li>\n",
    "<li><b>transform=transforms.ToTensor()</b> : تبدیل تصویر از <b>ماتریس numpy با مقادیر 0 تا 255</b> به <b>Tensor PyTorch با مقادیر 0 تا 1</b>. دلیل تبدیل: شبکه عصبی PyTorch روی Tensorها عمل می‌کند و مقیاس [0,1] باعث پایدارتر شدن آموزش می‌شود.</li>\n",
    "<li><b>batch_size</b> : تعداد نمونه‌هایی که در هر بار عبور از شبکه پردازش می‌شوند. اینجا 1 یعنی هر بار فقط یک تصویر پردازش می‌شود.</li>\n",
    "<li><b>shuffle</b> : اگر <code>True</code>، ترتیب تصاویر در هر epoch به صورت تصادفی انتخاب می‌شود تا شبکه ترتیب ثابت یاد نگیرد.</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33258bcc-9358-4c0d-a57a-ee9d4dc785bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        # لایه\\u200cها\\n        self.fc1 = nn.Linear(28*28, 128)  # ورودی: 784 پیکسل -> 128 نرون\\n        self.fc2 = nn.Linear(128, 64)     # 128 -> 64\\n        self.fc3 = nn.Linear(64, 10)      # 64 -> 10 خروجی (10 رقم)\\n\\n    def forward(self, x):\\n        # تبدیل تصویر 28x28 به یک وکتور 784تایی\\n        x = x.view(-1, 28*28)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)  # این خروجی Logits هست\\n        return x\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # لایه‌ها\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # ورودی: 784 پیکسل -> 128 نرون\n",
    "        self.fc2 = nn.Linear(128, 64)     # 128 -> 64\n",
    "        self.fc3 = nn.Linear(64, 10)      # 64 -> 10 خروجی (10 رقم)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # تبدیل تصویر 28x28 به یک وکتور 784تایی\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # این خروجی Logits هست\n",
    "        return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e096ed5-78f1-4f00-b701-a3cd889efa71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[0;32m      6\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 5  # تعداد دوره‌های آموزش\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be016a8-fb01-475c-b4d7-13fad444d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 4. گرفتن یک نمونه از دیتاست\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# 5. نمایش تصویر\n",
    "plt.imshow(images[0][0], cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels.item()}\")\n",
    "plt.show()\n",
    "\n",
    "# 6. عبور از شبکه\n",
    "model = SimpleCNN()   # شبکه‌ای که قبلا تعریف کردیم\n",
    "model.eval()    # حالت ارزیابی (غیر آموزشی)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)          # خروجی شبکه\n",
    "    _, predicted = torch.max(outputs, 1)  # گرفتن کلاس پیش‌بینی‌شده\n",
    "\n",
    "print(f\"شبکه پیش‌بینی کرد: {predicted.item()}  |  برچسب واقعی: {labels.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c22dcc-b596-4d3a-a3fe-12b39552928e",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "<b>import matplotlib.pyplot as plt</b><br>\n",
    "برای نمایش تصاویر استفاده می‌شود. ما از <b>plt.imshow</b> برای نشان دادن تصویر و از <b>plt.title</b> برای گذاشتن عنوان روی تصویر استفاده می‌کنیم.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>images, labels = next(iter(test_loader))</b><br>\n",
    "گرفتن یک نمونه (batch) از دیتاست تست. <br>\n",
    "- <b>iter(test_loader)</b> یک iterator روی دیتاست می‌سازد.<br>\n",
    "- <b>next()</b> اولین batch را می‌گیرد.<br>\n",
    "- چون <b>batch_size=1</b> است، <b>images</b> یک تصویر و <b>labels</b> برچسب آن را شامل می‌شود.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>plt.imshow(images[0][0], cmap=\"gray\")</b><br>\n",
    "نمایش تصویر MNIST. <br>\n",
    "- <b>images[0][0]</b>: تصویر اول و کانال اول (MNIST سیاه و سفید است).<br>\n",
    "- <b>cmap=\"gray\"</b>: تصویر سیاه و سفید نمایش داده می‌شود.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>plt.title(f\"Label: {labels.item()}\")</b><br>\n",
    "عنوان تصویر که برچسب واقعی آن را نمایش می‌دهد. <br>\n",
    "- <b>labels.item()</b> مقدار عددی برچسب را از تنسور استخراج می‌کند.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>plt.show()</b><br>\n",
    "تصویر را روی صفحه نمایش می‌دهد.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>model = Net()</b><br>\n",
    "ایجاد نمونه‌ای از شبکه عصبی که قبلاً تعریف شده است.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>model.eval()</b><br>\n",
    "مدل را در حالت ارزیابی قرار می‌دهد: <br>\n",
    "- Dropout و BatchNorm غیر فعال می‌شوند.<br>\n",
    "- دیگر گرادیان‌ها محاسبه نمی‌شوند.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>with torch.no_grad():</b><br>\n",
    "تمام عملیات داخل این بلاک بدون محاسبه گرادیان انجام می‌شود.<br>\n",
    "- صرفه‌جویی در حافظه و سرعت برای inferencing.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>outputs = model(images)</b><br>\n",
    "تصویر از شبکه عبور می‌کند و خروجی logits ۱۰کلاسه تولید می‌شود.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>_, predicted = torch.max(outputs, 1)</b><br>\n",
    "کلاس پیش‌بینی‌شده را می‌گیریم: <br>\n",
    "- <b>_</b>: مقدار حداکثر (ما نیاز نداریم).<br>\n",
    "- <b>predicted</b>: اندیس بیشترین مقدار = کلاس پیش‌بینی شده.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>print(f\"شبکه پیش‌بینی کرد: {predicted.item()}  |  برچسب واقعی: {labels.item()}\")</b><br>\n",
    "چاپ نتیجه:<br>\n",
    "- <b>predicted.item()</b>: کلاس پیش‌بینی‌شده توسط شبکه.<br>\n",
    "- <b>labels.item()</b>: برچسب واقعی تصویر.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b900a64-0a0b-4454-8703-687fe26e0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 2. بدون محاسبه گرادیان\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)                  # عبور تصویر از شبکه\n",
    "        _, predicted = torch.max(outputs, 1)    # گرفتن کلاس پیش‌بینی شده\n",
    "        total += labels.size(0)                 # جمع تعداد نمونه‌ها\n",
    "        correct += (predicted == labels).sum().item()  # جمع تعداد پیش‌بینی درست\n",
    "\n",
    "# 3. محاسبه دقت\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"دقت شبکه روی دیتاست تست: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02021127-3e1f-44fd-b608-40bd05bdfc36",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "<b>model = Net()</b><br>\n",
    "نمونه‌ای از شبکه عصبی ایجاد می‌کنیم.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>model.eval()</b><br>\n",
    "مدل را در حالت ارزیابی قرار می‌دهیم تا Dropout و BatchNorm غیرفعال شوند.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>correct = 0  |  total = 0</b><br>\n",
    "متغیرهایی برای شمارش تعداد پیش‌بینی‌های درست و کل نمونه‌ها.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>with torch.no_grad():</b><br>\n",
    "تمام محاسبات داخل این بلاک بدون محاسبه گرادیان انجام می‌شوند.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>for images, labels in test_loader:</b><br>\n",
    "یک حلقه روی دیتاست تست می‌زنیم تا همه تصاویر عبور داده شوند.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>outputs = model(images)</b><br>\n",
    "تصویر از شبکه عبور می‌کند و logits کلاس‌ها تولید می‌شوند.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>_, predicted = torch.max(outputs, 1)</b><br>\n",
    "کلاس پیش‌بینی شده را با بیشترین مقدار logits انتخاب می‌کنیم.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>total += labels.size(0)</b><br>\n",
    "تعداد نمونه‌ها را جمع می‌کنیم تا برای محاسبه دقت استفاده شود.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>correct += (predicted == labels).sum().item()</b><br>\n",
    "مقایسه پیش‌بینی با برچسب واقعی و جمع تعداد درست‌ها.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>accuracy = 100 * correct / total</b><br>\n",
    "محاسبه درصد دقت شبکه روی کل دیتاست تست.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\">\n",
    "<b>print(f\"دقت شبکه روی دیتاست تست: {accuracy:.2f}%\")</b><br>\n",
    "نمایش دقت نهایی روی صفحه.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab247b-f73a-47fc-9233-8cf5ed3d6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"دقت شبکه روی دیتاست تست: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
