. افزایش عمق مدل

مدل قبلی فقط یک لایه Conv2D و یک MaxPooling داشت.
من اینجا:

دو لایه کانولوشن پشت سر هم گذاشتم:

Conv2D(64 فیلتر) → استخراج ویژگی‌های ساده (لبه‌ها، خطوط)

Conv2D(128 فیلتر) → استخراج ویژگی‌های پیچیده‌تر (الگوهای جزئیات بالا)

این عمق بیشتر باعث میشه مدل ویژگی‌های تصویر رو در سطوح مختلف یاد بگیره.

2. افزایش ظرفیت مدل

مدل ساده تعداد فیلتر کمی داشت (مثلاً 32 و 64).
من تعداد فیلترها رو زیاد کردم:

64 فیلتر در لایه اول

128 فیلتر در لایه دوم
این باعث میشه مدل ویژگی‌های متنوع‌تری رو استخراج کنه.

3. استفاده از Dropout برای جلوگیری از overfitting

مدل عمیق‌تر اگر بدون کنترل باشه، روی داده آموزش حفظ میشه ولی روی داده جدید ضعیف عمل می‌کنه.
برای جلوگیری:

بعد از هر MaxPooling → Dropout(0.25) گذاشتم

قبل از لایه خروجی → Dropout(0.5) گذاشتم
این یعنی بخشی از نورون‌ها در هر مرحله آموزش غیرفعال میشن و مدل مجبور میشه ویژگی‌های متنوع یاد بگیره.

4. افزایش تعداد Epoch

مدل قبلی شاید ۵ یا ۱۰ epoch آموزش می‌دید.
من اینجا:

15 epoch گذاشتم تا مدل فرصت بیشتری برای یادگیری پیدا کنه.

5. استفاده از Adam با learning rate بهینه

به جای SGD، از:
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

استفاده کردم، چون Adam به طور خودکار نرخ یادگیری رو تطبیق میده.

نتیجه این تغییرات

مدل قبلی: دقت حدود 97–98%

مدل بهبود یافته: دقت 99%+ روی MNIST
(به خاطر ظرفیت بیشتر + یادگیری بهتر + جلوگیری از overfitting)
